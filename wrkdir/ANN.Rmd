---
title: "R Notebook"
output: html_notebook
---


## Problem1— Using ANN for Classifying News Articles
For this problem, we are going to use reuters dataset. It is a set of short newswires along with their topics
published by Reuters in 1986. It is a simple, widely used toy dastaset for text classification. You are
going to use a simple feedforward neural network to classify reuters news into 46 different
topics/classes.
The reuters dataset comes packaged as part of Keras . Import the dataset from keras using the following
commands:
```{r}
library(keras)
reuters = dataset_reuters(num_words=10000)
```

Take a look at the structure of reuters.dataset. The dataset is already pre-processed and split into train
and test sets. Each example in the train or test set represents a news article and is stored as a list of
integers where each integer represents the index of a specific word appearing in that article. When you
set num_words=1000 in dataset_reuters, then keras keeps only the top 10000 most frequent words in the
data. Let’s take a look at the structure of the training examples:

```{r}
str(reuters$train$x)
```

This means that the first article consists of the words with indices 1,2,2,8,etc.
As you can see, the examples in the train and test data are vectors of varying lengths. Neural Networks
requires a matrix where each row represents an example and each column represent an attribute of that
example. Therefore, to prepare this data for neural networks we need to make sure that all examples
have the same number of columns ( that is, they are vectors of the same length). To do this, we do one-
hot encoding of each example to turn them into vectors of 0s and 1s. This would mean for instance,
turning the sequence [1,2,2,8,....] into a 10000 dimensional vector that would be all zeros except for
indices 1,2,8, etc. In other words, we turn each news article into a 10000 dimensional binary vector
which indicates which of the top 10000 frequent words occur in that article. You can use the following
r function to do this one-hot-encoding:

```{r}
one_hot_encoding = function(x, dimension=10000) {
  encoded = matrix(0, length(x), dimension)
  for (i in 1:length(x))
  encoded[i, x[[i]]] = 1
  encoded
}
```

Where x is the list of examples for which you want to do one-hot-encoding. Call this function on
reuters\$train\$x and reuters\$test\$x to get the one-hot encoding of the train and test examples. This will
produce a matrix with dimensions (8982,10000) for the train data and a matrix with dimensions(2246,
10000) for the test data. You can now use these matrices to train and test your neural network model.

```{r}
reuters_train = one_hot_encoding(reuters$train$x)
reuters_test = one_hot_encoding(reuters$test$x)
```

__Q1. (5 pts)__ Create an ANN model to classify reuters news article into 46 classes (note that
reuters\$train\$y and reuters\$test\$y are vectors of integers between 0-45 representing the category of
each news article). Use at least two hidden layers and compute the accuracy of your model on the test
set.
Unlike the fashion Mnist dataset where each image had to be flattened into a one dimensional vector,
for the reuters dataset, you do not need the flatten layer before the dense layer as each observation
(news article) is already one dimensional.

```{r}
model <- keras_model_sequential()
model %>%
        layer_dense( units = 50, activation = "relu", input_shape = 10000) %>%
        layer_dense( units = 50, activation = "relu") %>%
        layer_dense( units = 50, activation = "relu") %>%
        layer_dense(units = 46, activation = 'softmax')
```
```{r}
set.seed(123)
model %>% compile (
     loss = 'sparse_categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy')
```
```{r}
history = model %>% fit (x = reuters_train, y = reuters$train$y)
```
```{r}
score <- model %>% evaluate(reuters_test, reuters$test$y, verbose = 2)

cat('Test accuracy:', score[2], "\n")
```

__Q2. (5 pts)__ Split the train data into train/validation set. Use the first 1000 examples in reuters$train for
validation and the rest for training your model. Use “tfruns” package to tune your ANN’s hyperparameters including, the number of nodes in each hidden layer, the activation function in each hidden
layer, batch_size, learning_rate, and the number of epochs). Validate each model on the validation set.  
Answer the following questions:  
      1- Which model ( which hyper-parameter combination) resulted in the best accuracy on the
      validation data? Make sure that you print the returned value from tfruns and report the  
      run with the highest validation accuracy.  
      2- Print the learning curve of your best model. Does your best model still overfit?  
      3- Does your validation_loss stop decreasing after several epochs? If so, at roughly which epoch  
      does your validation_loss stop decreasing?

```{r}
reuters_validation_x = one_hot_encoding(reuters$train$x[1:1000])
validation_labels = reuters$train$y[1:1000]

reuters_train = one_hot_encoding(reuters$train$x[1001:length(reuters$train$x)])
reuters_train_labels = reuters$train$y[1001:length(reuters$train$y)]
```
```{r}
library(tfruns)
```
```{r}
runs <- tuning_run("reuters.R",
                   flags = list (
                     nodes = c(64, 128, 392),
                     learning_rate = c(0.01, 0.05, 0.001, 0.0001),
                     batch_size = c(100, 200, 500, 1000),
                     epochs = c(30,50,100),
                     activation = c("relu","sigmoid","tanh")
                   ), sample = 0.02)
```
```{r}
runs
```
1. The model with the best validation accuracy was the model from the first run
2. see attached for plot of best training run
3. the validation error stops decreasing after the 13th epoch

__Q3. (5 pts)__ Now use ALL the training data in reuters$train (i.e., train + validation data) to train an
ANN with the best hyper- parameter combination you found after tuning in the previous question.
Compute the accuracy of this model on the test set.

```{r}
reuters_train = one_hot_encoding(reuters$train$x)
reuters_test = one_hot_encoding(reuters$test$x)
```

```{r}
model <- keras_model_sequential()
model %>%
        layer_dense( units = 128, activation = "tanh", input_shape = 10000) %>%
        layer_dense( units = 128, activation = "tanh") %>%
        layer_dense( units = 128, activation = "tanh") %>%
        layer_dense(units = 46, activation = 'softmax')
```

```{r}
set.seed(123)
model %>% compile (
        loss = 'sparse_categorical_crossentropy',
        optimizer = optimizer_adam(lr=0.0001),
        metrics = 'accuracy')

model %>% fit (x = reuters_train, y = reuters$train$y, epochs = 30, batch_size = 100)
```

```{r}
history = model %>% fit (x = reuters_train, y = reuters$train$y)
```
```{r}
history
```


## Problem2——Predicting Baseball players’ salaries

1. (1p) Download the dataset hitters.csv and explore the overall structure of the dataset using the
str() function. Get a summary statistics of each variable. Answer the following questions:
a) How many observations do you have in the data?
b) How many categorical and numeric variables you have in your data?
c) Is there any missing value?
d) Draw the histogram of salary. Interpret what you see in the histogram.

```{r}
hitters = read.csv("hitters.csv")
```
```{r}
str(hitters)
summary(hitters)
```

a) There are 322 observations
b) There are 3 categorical variables and 17 numeric variables
c) There are 59 missing values in salary
d) The histogram is skewed right and the mean is around 500
```{r}
hist(hitters$Salary)
```

2. (1p) remove the observation for which Salary value is missing
```{r}
hitters_clean = hitters[!is.na(hitters$Salary),]
```

3. (2 pt) Which predictors have most correlation with Salary? Use scattered plot, side-by-side box
plots, t-test and correlation matrix to answer this question.

```{r}
plot(hitters_clean[ , c(19, 1:4)])
plot(hitters_clean[ , c(19, 5:9)])
plot(hitters_clean[ , c(19, 10:13)])
plot(hitters_clean[ , c(19, 16:18)])
```
```{r}
boxplot(Salary~League,data = hitters_clean)
boxplot(Salary~Division,data = hitters_clean)
boxplot(Salary~NewLeague,data = hitters_clean)
```

```{r}
t.test(Salary~League, data = hitters_clean)
t.test(Salary~Division,data = hitters_clean)
t.test(Salary~NewLeague,data = hitters_clean)
```

```{r}
cor(hitters_clean$Salary, y=hitters_clean[-c(19, 15, 14, 20)])
```

CAtBat, CHits, CHmRun, CRuns, and CRBI have correlations greater than .5

4. Use set.seed(1) to set the random seed so I can reproduce your results.
```{r}
set.seed(1)
```

5. Use Caret’s “createDataPartition” method as follows to partition the dataset into
hitters_train, and hitters_test (use 90% for training and 10% for testing)

```{r}
inTrain = createDataPartition(hitters_clean$Salary, p=0.9, list=FALSE)
hitters_train = hitters_clean[inTrain,]
hitters_test = hitters_clean[-inTrain,]
```

6. (1pt) Neural networks do not accept categorical variables and we must encode the categorical
variables before training the network. All the categorical variables in this dataset are binary ( i.e.,
have two levels) so you can encode them by simply using iflese function to convert each to a
numeric variable with two values 0 and 1.

```{r}
hitters_train$NewLeague = ifelse(hitters_train$NewLeague == "N", 1, 0)
hitters_train$Division = ifelse(hitters_train$Division == "W", 1, 0)
hitters_train$League = ifelse(hitters_train$League == "N", 1, 0)
```

7. (1pt)Replace the salary column with log(salary) where log is the logarithm function. This will be
the attribute we want to predict. 
```{r}
hitters_train$Salary = log(hitters_train$Salary)
```

8. (1pt) Set.seed(1) and further divide the hitters_train data into 90% training and 10% validation
using Caret’s “CreateDataPartition” function

```{r}
toTrain = createDataPartition(hitters_train$Salary, p=0.9, list=FALSE)
hitters_train = hitters_train[toTrain , ]
hitters_val = hitters_train[-toTrain , ]
```

9. ( 3 pt) Scale the numeric attributes in the training data (except for the outcome variable, Salary).
Use the column means and column standard deviations from the training data to scale both the
validation and test data (please refer to slide 81, lecture 9). Note: __You should not scale the__
__dummy variables you created in step 6.__ You can append the categorical variables to your scaled
numeric variables.

```{r}
hitters_scale_train = scale(hitters_train[-c(14,15,20,19)])

hitters_mean_train = attr(hitters_scale_train, "scaled:center")
hitters_stddevs_train = attr(hitters_scale_train, "scaled:scale")

hitters_scale_train = as.data.frame(hitters_scale_train)
hitters_train_labels = hitters_train[,19]
hitters_scale_train$Salary = NULL

hitters_scale_train$League = hitters_train[,14]
hitters_scale_train$Division = hitters_train[,15]
hitters_scale_train$NewLeague = hitters_train[,20]

hitters_scale_val = as.data.frame(scale(hitters_val[-c(14,15,20,19)], center = hitters_mean_train, scale = hitters_stddevs_train))
hitters_val_labels = hitters_val[,19]
hitters_scale_val$Salary = NULL
hitters_scale_val$League = hitters_val[,14]
hitters_scale_val$Division = hitters_val[,15]
hitters_scale_val$NewLeague = hitters_val[,20]

hitters_scale_test = as.data.frame(scale(hitters_test[-c(14,15,20,19)], center = hitters_mean_train, scale = hitters_stddevs_train))
hitters_test_labels = hitters_test[,19]
hitters_scale_test$Salary = NULL
hitters_scale_test$League = hitters_test[,14]
hitters_scale_test$Division = hitters_test[,15]
hitters_scale_test$NewLeague = hitters_test[,20]
```

9 cont. (5 pt) Create an ANN model to predict log(salary) from other attributes. Use at least two hidden
layers. Use tfruns to tune your model’s hyper-parameters including, the number of nodes in each
hidden layer, the activation function in each hidden layer, batch_size, learning_rate, and the number of
epochs). Validate each model on the validation set. Answer the following questions:

```{r}
library(tfruns)
```
```{r}
runs <- tuning_run("hitters.R",
                   flags = list (
                     nodes = c(64, 128, 392),
                     learning_rate = c(0.01, 0.05, 0.001, 0.0001),
                     batch_size = c(100, 200, 500, 1000),
                     epochs = c(30, 50, 100),
                     activation = c("relu","sigmoid","tanh")
                   ), sample = 0.02)
```

```{r}
runs
```
• Print the returned value from tf_runs to see the metrics for each run. Which run ( which
hyper-parameter combination) gave the best mean squared error on the validation data?

The combination from the third run

• Print the learning curve for your best model. Does your best model still overfit?

Yes, the validation loss is less than the metric loss

• Does your validation_loss stop decreasing after several epochs? If so, at roughly which epoch
does your validation_loss stop decreasing?

Yes, it stops decreasing at the 94th epoch.

10. (5 pt) Measure the performance of your best model (after tuning) on the test set and
compute its RMSE. Note that you must reverse the log transformation by
taking the exp (exponent) of the predictions returned by the neural network
model and compare it to the original salary value ( without log
transformation). Doing this, helps us get the RMSE in the original scale.